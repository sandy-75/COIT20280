{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0ab6c576cf668ff14d29f0d02eb553fc3cd559ce35bc756069a1f2fa3e90fc2ba",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ab6c576cf668ff14d29f0d02eb553fc3cd559ce35bc756069a1f2fa3e90fc2ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Module 5 #\n",
    "### Expected Time to Complete: 10 hrs <tba>###\n",
    "### Total Marks: 18 marks <tba>### "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## About ##"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This Jupyter Notebook contains all of the portfolio assessment related to Module 6. The assessment tasks start off with some simple data I/O tasks and gradually build up to more complicated data access tasks that deal with different formats and different platforms. The focus of these tasks is on building the skills that are required for accessing data - from very simple data I/O to more complex data access. Such skills are a critical but often overlooked part of data analysis. We will also be working with data from our case study 'Credit Card Fraud Detection' in this notebook. Cyber Analytics is the broader theme of the course so we try to ensure that you have as many opportunities as possible to work with that type of data. \n",
    "\n",
    "Please ensure you refer to the marking rubric for this assessment item while completing the following assessment tasks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 1 - Data Access Basics (3.5 marks)## \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 1.1 - Data Access Fundamentals ###"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following along with Mark Quinn's (2017) YouTube video on basic data I/O write a block of code that takes a 7 digit user security code plus their username and displays it to the screen. Also include a check on the security code. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 1.2 - Formatting Output ###"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the official python docs tutorial as a reference use formatted string literals (f-strings) to output a customer name and their credit card number using appropriate variables. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform the same function as in the above but with the str.format() method. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using f-strings create a table that has two columns (customer name, credit card number) and four rows of data. Output this in a way that ensures the columns will always line up (hint: ensure a minimum number of characters via ':')  (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform the same as in the above but using the string format method (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try this now with manual string formatting using a combination of left and right jusification for the customer name and credit card numbers. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now the same thing using old string formatting (ie. % operator) (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2 - Accessing Data: Different Formats, Different Plaforms (8.5 marks) ##\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2.1 - Reading and Writing Files ###"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following the official python docs tutorial create and open a file called customers in read and write mode. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you wanted to avoid problems caused by loading an extremely large file into memory show how you would do so. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show two different methods for reading lines from a file (all of the lines). (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the customers file you created previously write the following customer value to the file. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "customers = ('Jane Doe', 47, 78965432)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show how you would write the following dictionary to a file called 'security_customers'. Make sure you do so in a way that is easy, allows for interoperability and incorporates best practice. (0.5 marks)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "customers = {50789: {'name': 'Baptiste', 'age': '52', 'status': 0},\n",
    "             72658: {'name': 'Helena', 'age': '26', 'status': 1}}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2.2 - Files and Exceptions###"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Append the following customers to your previously created file 'security_customers'. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_customers = {60793: {'name': 'Mary', 'age': '15', 'status': 1},\n",
    "             72658: {'name': 'Barry', 'age': '32', 'status': 1}}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Open the file 'security_customers' and read the entire file. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write an exception block for the case where the file doesn't exist. To avoid a FileNotFoundError allow the program to fail silently. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write a more appropriate exception block for the case where the file does not exist. In this case provide a useful message to the user. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2.3 - Pandas IO tools and different data formats ###\n",
    "There are no associated exercises for this section. This section simply refers to the pandas documentation which you should familiarise yourself with here (https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) . Take this opportunity - if you haven't done so already - to take a look at this documentation. This documentation will prove useful in the following sections. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2.4 - Data Loading, Storage and File Formats###"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section we are going to start working with a data set that is specific to the cyber analytics context. This is the Kaggle Credit card fraud data set which can be found here: https://www.kaggle.com/mlg-ulb/creditcardfraud "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using McKinney(2017) as a guide load the Kaggle credit card data into a pandas dataframe. Make sure that you account for the column names appropriately (demonstrating that you have taken time to understand the data) as well as potential missing values. As this is a csv make sure to use the pandas.read_csv() reader to do so. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are a number of different methods to find out how much memory is consumed by the dataframe: sys.getsizeof(df), df.memory_usage() and df.info(). There is a discussion on stackoverflow on this here https://stackoverflow.com/questions/18089667/how-to-estimate-how-much-memory-a-pandas-dataframe-will-need/47751572 . Use one of these methods to find out how much memory your dataframe in the previous step takes up.  (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Provide commentary below on whether this particular file is considered 'large' and exactly what impact this has. Either demonstrate this with code or provide references to back up your assertion. Lee (2017) (https://towardsdatascience.com/why-and-how-to-use-pandas-with-large-data-9594dda2ea4c) is a reasonable reference point to start with here. However, you might find some better references yourself. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show the four official ways that the pandas docs suggest for avoiding taking up too much memory by reading a large file. (see https://pandas.pydata.org/pandas-docs/stable/user_guide/scale.html) Demonstrate this with the Kaggle data set. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Pandas documentation introduced in Section 2.3 show how to look at performance metrics for different IO methods (https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#performance-considerations). Reproduce this here but use the Kaggle data to do so. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comment on what your top three performers are in terms of speed. How does this relate to the pandas documentation? If there are differences comment on why you believe there are differences. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on these tests plus what you know about these methods what would your recommended IO method be for this particular data set? Justify your recommendation. Remember all IO methods have their advantages and disadvantages. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write the Kaggle data set to a sqlite database and then show how you would load this data from the database into a pandas dataframe. (0.5 marks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 3 - Creating Coherent Data Sets: PCAP mini-project (6 marks) ##"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following sections of this notebook you should address the following requirements:\n",
    "\n",
    "    1) Use scapy to explore and understand data in a pcap file (Read the pcap file, explore a single item in the pcap, understand object types in scapy and importing layers) (3 marks for demonstrating exploration and understanding in this step)\n",
    "    2) Convert data in your pcap file to a workable Pandas DataFrame (2 marks)\n",
    "    3) Write your dataframe to a csv file (4 columns only: source address, destination adress, source port and destination port) (1 mark)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For 1) and 2) above we recommend Ronald Eddings blog post 'Learning Packet Analysis with Data Science' for his overview of pcap, python and pandas (https://medium.com/hackervalleystudio/learning-packet-analysis-with-data-science-5356a3340d4e).  Following along with his tutorial may simply be a little too difficult for some however - the downloads are quite large and sniffing packets on your own system may not be practical for many due to permissions (you must be root). However, Eddings Jupyter Notebook on github (https://github.com/secdevopsai/Packet-Analytics/blob/master/Packet-Analytics.ipynb) and the official Scapy docs (https://scapy.readthedocs.io/en/latest/introduction.html) provide enough information for you to explore and understand data in a pcap file. To make things a little easier we have provided you with a pcap file to use EK_MALWARE_2014-08-01-Nuclear-EK-traffic_mailware-traffic-analysis.net.pcap. You can get this file from GitHub here (https://github.com/sandy-75/COIT20280). This pcap file was sourced from a bank of malicious and exploit pcaps from Contagio (http://contagiodump.blogspot.com/2013/04/collection-of-pcap-files-from-malware.html). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}